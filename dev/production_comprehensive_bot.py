#!/usr/bin/env python3
"""
üöÄ PRODUCTION ET:LEGACY DISCORD BOT - COMPREHENSIVE VERSION
=========================================================
Full production bot with SSH file monitoring, real data import, and comprehensive stats.

Features:
- SSH monitoring of game server: et@puran:/home/et/.etlegacy/legacy/gamestats/
- Smart import: only NEW files (tracks processed files to avoid duplicates)
- Real C0RNP0RN3.lua data parsing and comprehensive database storage
- Discord @mention support with player linking
- All C0RNP0RN3.lua data: 28 weapons, multikills, objectives, damage analytics
- Production-ready with error handling and logging

Commands:
- !stats @user - Overall comprehensive stats  
- !stats @user 30.9.2025 - Date-specific stats
- !session_stats 30.9 - All players from that session
- !link playername - Link Discord to ET:Legacy GUID
- !start_monitoring - Start SSH file monitoring (admin only)
- !stop_monitoring - Stop SSH file monitoring (admin only)
- !import_status - Show import statistics
"""

import discord
from discord.ext import commands, tasks
import sqlite3
import os
import sys
import asyncio
import logging
import re
from datetime import datetime, date, timedelta
from typing import Optional, Dict, Any, List
import hashlib
from pathlib import Path

# SSH imports for file monitoring
try:
    import paramiko
    import asyncssh
    SSH_AVAILABLE = True
except ImportError:
    SSH_AVAILABLE = False
    print("‚ö†Ô∏è SSH libraries not available. Install: pip install paramiko asyncssh")

# Add the bot directory to path to import our parser
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'bot'))

try:
    from community_stats_parser import C0RNP0RN3StatsParser
    PARSER_AVAILABLE = True
except ImportError:
    PARSER_AVAILABLE = False
    print("‚ùå C0RNP0RN3StatsParser not available")

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/production_bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('ProductionBot')

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

class SSHFileMonitor:
    """SSH-based file monitoring for game server stats directory"""
    
    def __init__(self, host: str, username: str, remote_path: str, key_path: str = None):
        self.host = host
        self.username = username
        self.remote_path = remote_path
        self.key_path = key_path
        self.is_monitoring = False
        self.processed_files = set()
        self.last_check = datetime.now()
        
    async def connect(self):
        """Establish SSH connection"""
        try:
            if self.key_path:
                self.ssh_client = await asyncssh.connect(
                    self.host,
                    username=self.username,
                    client_keys=[self.key_path],
                    known_hosts=None
                )
            else:
                # Use SSH agent or password-based auth
                self.ssh_client = await asyncssh.connect(
                    self.host,
                    username=self.username,
                    known_hosts=None
                )
            logger.info(f"‚úÖ SSH connected to {self.username}@{self.host}")
            return True
        except Exception as e:
            logger.error(f"‚ùå SSH connection failed: {e}")
            return False
    
    async def get_new_files(self, since_time: datetime = None) -> List[str]:
        """Get list of new .txt files created after since_time"""
        if since_time is None:
            since_time = self.last_check
            
        try:
            # List files with timestamps
            cmd = f'find {self.remote_path} -name "*.txt" -newer /tmp/botcheck -ls 2>/dev/null || find {self.remote_path} -name "*.txt" -mmin -60'
            result = await self.ssh_client.run(cmd)
            
            new_files = []
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    if line and '.txt' in line:
                        # Extract filename from find output
                        filename = line.split()[-1] if line.split() else None
                        if filename and filename not in self.processed_files:
                            new_files.append(filename)
            
            logger.info(f"üìÅ Found {len(new_files)} new files")
            return new_files
            
        except Exception as e:
            logger.error(f"‚ùå Error checking for new files: {e}")
            return []
    
    async def download_file(self, remote_file: str, local_path: str) -> bool:
        """Download a file from remote server"""
        try:
            await asyncssh.scp((self.ssh_client, remote_file), local_path)
            logger.info(f"üì• Downloaded: {os.path.basename(remote_file)}")
            return True
        except Exception as e:
            logger.error(f"‚ùå Download failed for {remote_file}: {e}")
            return False
    
    async def mark_file_processed(self, filename: str):
        """Mark a file as processed to avoid re-importing"""
        self.processed_files.add(filename)
        
    async def disconnect(self):
        """Close SSH connection"""
        if hasattr(self, 'ssh_client'):
            self.ssh_client.close()
            await self.ssh_client.wait_closed()

class ComprehensiveStatsCommands(commands.Cog):
    """Comprehensive stats commands with real data support"""
    
    def __init__(self, bot):
        self.bot = bot
        self.db_path = bot.db_path
        self.parser = C0RNP0RN3StatsParser() if PARSER_AVAILABLE else None
        
    async def get_player_guid_from_mention(self, mention: str) -> Optional[str]:
        """Get player GUID from Discord mention"""
        # Extract Discord ID from mention
        discord_id = None
        if mention.startswith('<@') and mention.endswith('>'):
            discord_id = mention[2:-1]
            if discord_id.startswith('!'):
                discord_id = discord_id[1:]
        else:
            # Try direct name lookup
            mention = mention.strip('@')
            
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if discord_id:
            cursor.execute("SELECT player_guid FROM player_links WHERE discord_id = ?", (discord_id,))
        else:
            cursor.execute("SELECT player_guid FROM player_links WHERE discord_username LIKE ?", (f"%{mention}%",))
            
        result = cursor.fetchone()
        conn.close()
        
        return result[0] if result else None

    @commands.command(name='stats')
    async def stats_command(self, ctx, player: str = None, date_filter: str = None):
        """
        Show comprehensive player statistics
        Usage: !stats @user or !stats @user 30.9.2025
        """
        if not player:
            await ctx.send("‚ùå Please specify a player: `!stats @username` or `!stats playername`")
            return
            
        # Get player GUID
        player_guid = await self.get_player_guid_from_mention(player)
        if not player_guid:
            # Try direct name search
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT player_guid FROM player_comprehensive_stats 
                WHERE LOWER(clean_name) LIKE LOWER(?) OR LOWER(player_name) LIKE LOWER(?)
            """, (f"%{player}%", f"%{player}%"))
            result = cursor.fetchone()
            conn.close()
            
            if not result:
                await ctx.send(f"‚ùå Player '{player}' not found. Use `!link {player}` to link them to Discord.")
                return
            player_guid = result[0]
        
        # Parse date filter if provided
        date_condition = ""
        date_params = []
        if date_filter:
            try:
                parts = date_filter.split('.')
                if len(parts) == 2:
                    day, month = parts
                    year = str(datetime.now().year)
                else:
                    day, month, year = parts
                    
                date_str = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                date_condition = "AND DATE(s.session_date) = ?"
                date_params = [date_str]
            except:
                await ctx.send("‚ùå Invalid date format. Use DD.MM or DD.MM.YYYY")
                return
        
        # Get comprehensive stats
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Main stats query with comprehensive data
        cursor.execute(f"""
            SELECT 
                pcs.clean_name,
                COUNT(*) as total_rounds,
                SUM(pcs.kills) as total_kills,
                SUM(pcs.deaths) as total_deaths,
                SUM(pcs.damage_given) as total_damage,
                SUM(pcs.headshot_kills) as total_headshots,
                AVG(pcs.accuracy) as avg_accuracy,
                AVG(pcs.dpm) as avg_dpm,
                MAX(pcs.killing_spree_best) as best_spree,
                SUM(pcs.double_kills) as double_kills,
                SUM(pcs.triple_kills) as triple_kills,
                SUM(pcs.dynamites_planted) as dynamites_planted,
                SUM(pcs.objectives_stolen) as objectives_stolen,
                SUM(pcs.time_played_minutes) as total_playtime
            FROM player_comprehensive_stats pcs
            JOIN sessions s ON pcs.session_id = s.id
            WHERE pcs.player_guid = ? {date_condition}
            GROUP BY pcs.player_guid
        """, [player_guid] + date_params)
        
        stats = cursor.fetchone()
        if not stats:
            await ctx.send(f"‚ùå No stats found for player")
            return
            
        # Create comprehensive embed
        name, rounds, kills, deaths, damage, headshots, accuracy, dpm, best_spree, \
        double_kills, triple_kills, dynamites, objectives, playtime = stats
        
        kd_ratio = round(kills / max(deaths, 1), 2)
        hs_ratio = round((headshots / max(kills, 1)) * 100, 1) if kills > 0 else 0
        
        embed = discord.Embed(
            title=f"üìä {name} - Comprehensive Stats",
            color=0x00ff00 if kd_ratio > 1.5 else 0xffff00 if kd_ratio > 1.0 else 0xff0000
        )
        
        # Main combat stats
        embed.add_field(
            name="üéØ Combat Performance",
            value=f"**Kills:** {kills:,}\n**Deaths:** {deaths:,}\n**K/D:** {kd_ratio}\n**Damage:** {damage:,}",
            inline=True
        )
        
        # Accuracy and headshots
        embed.add_field(
            name="üé™ Accuracy & Headshots", 
            value=f"**Accuracy:** {accuracy:.1f}%\n**Headshots:** {headshots:,}\n**HS Ratio:** {hs_ratio}%\n**DPM:** {dpm:.1f}",
            inline=True
        )
        
        # Advanced stats
        embed.add_field(
            name="üèÜ Advanced Stats",
            value=f"**Best Spree:** {best_spree}\n**Double Kills:** {double_kills}\n**Triple Kills:** {triple_kills}\n**Playtime:** {playtime:.1f}m",
            inline=True
        )
        
        # Objectives
        embed.add_field(
            name="üéØ Objectives",
            value=f"**Dynamites:** {dynamites}\n**Flags Stolen:** {objectives}\n**Rounds:** {rounds}",
            inline=True
        )
        
        embed.set_footer(text=f"Data from C0RNP0RN3.lua ‚Ä¢ GUID: {player_guid}")
        conn.close()
        
        await ctx.send(embed=embed)

    @commands.command(name='session_stats')
    async def session_stats_command(self, ctx, date: str = None):
        """Show session statistics for all players on a date"""
        if not date:
            await ctx.send("‚ùå Please specify a date: `!session_stats 30.9` or `!session_stats 30.9.2025`")
            return
            
        # Format date
        try:
            parts = date.split('.')
            if len(parts) == 2:
                day, month = parts
                year = str(datetime.now().year)
            else:
                day, month, year = parts
                
            date_filter = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        except:
            await ctx.send("‚ùå Invalid date format. Use DD.MM or DD.MM.YYYY")
            return
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get top players for that date
        cursor.execute("""
            SELECT 
                pcs.clean_name,
                SUM(pcs.kills) as kills,
                SUM(pcs.deaths) as deaths,
                AVG(pcs.dpm) as dpm,
                SUM(pcs.headshot_kills) as headshots
            FROM player_comprehensive_stats pcs
            JOIN sessions s ON pcs.session_id = s.id
            WHERE DATE(s.session_date) = ?
            GROUP BY pcs.player_guid, pcs.clean_name
            ORDER BY kills DESC
            LIMIT 10
        """, (date_filter,))
        
        players = cursor.fetchall()
        conn.close()
        
        if not players:
            await ctx.send(f"‚ùå No sessions found for {date}")
            return
            
        embed = discord.Embed(title=f"üìÖ Session Stats - {date}", color=0x0099ff)
        
        leaderboard = ""
        for i, (name, kills, deaths, dpm, headshots) in enumerate(players, 1):
            kd = round(kills / max(deaths, 1), 2)
            leaderboard += f"{i}. **{name}** - {kills}K/{deaths}D (K/D: {kd}, DPM: {dpm:.1f})\n"
            
        embed.add_field(name="üèÜ Leaderboard", value=leaderboard, inline=False)
        embed.set_footer(text="Data from C0RNP0RN3.lua comprehensive tracking")
        
        await ctx.send(embed=embed)

    @commands.command(name='link')
    async def link_command(self, ctx, player_name: str):
        """Link your Discord account to an ET:Legacy player"""
        discord_id = str(ctx.author.id)
        discord_username = f"{ctx.author.name}#{ctx.author.discriminator}"
        
        # Search for player by name
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT DISTINCT player_guid, clean_name 
            FROM player_comprehensive_stats 
            WHERE LOWER(clean_name) LIKE LOWER(?) OR LOWER(player_name) LIKE LOWER(?)
        """, (f"%{player_name}%", f"%{player_name}%"))
        
        matches = cursor.fetchall()
        
        if not matches:
            await ctx.send(f"‚ùå No player found matching '{player_name}'")
            conn.close()
            return
            
        if len(matches) > 1:
            match_list = "\n".join([f"‚Ä¢ {name} ({guid})" for guid, name in matches])
            await ctx.send(f"‚ùå Multiple players found:\n{match_list}\nPlease be more specific.")
            conn.close()
            return
            
        player_guid, clean_name = matches[0]
        
        # Create or update link
        cursor.execute("""
            INSERT OR REPLACE INTO player_links 
            (player_guid, discord_id, discord_username, player_name)
            VALUES (?, ?, ?, ?)
        """, (player_guid, discord_id, discord_username, clean_name))
        
        conn.commit()
        conn.close()
        
        await ctx.send(f"‚úÖ Linked {ctx.author.mention} to **{clean_name}** (GUID: {player_guid})")

class ProductionETLegacyBot(commands.Bot):
    """Production ET:Legacy Discord Bot with SSH monitoring"""
    
    def __init__(self):
        intents = discord.Intents.default()
        intents.message_content = True
        super().__init__(command_prefix='!', intents=intents)
        
        # Configuration
        self.db_path = "dev/etlegacy_comprehensive.db"
        self.parser = C0RNP0RN3StatsParser() if PARSER_AVAILABLE else None
        
        # SSH monitoring configuration
        self.ssh_host = os.getenv('SSH_HOST', 'puran')  # Game server hostname
        self.ssh_user = os.getenv('SSH_USER', 'et')
        self.ssh_key_path = os.getenv('SSH_KEY_PATH')  # Path to SSH private key
        self.remote_stats_path = '/home/et/.etlegacy/legacy/gamestats'
        self.local_temp_dir = 'temp_stats'
        
        # Monitoring state
        self.monitor = None
        self.is_monitoring = False
        self.admin_users = set(os.getenv('ADMIN_DISCORD_IDS', '').split(','))
        
        # Create temp directory
        os.makedirs(self.local_temp_dir, exist_ok=True)
        
    async def setup_hook(self):
        """Initialize bot components"""
        await self.add_cog(ComprehensiveStatsCommands(self))
        await self.initialize_database()
        await self.load_processed_files()
        
        # Start monitoring task
        if not self.monitor_new_files.is_running():
            self.monitor_new_files.start()
            
        logger.info("ü§ñ Production bot setup complete")
        
    async def initialize_database(self):
        """Ensure comprehensive database schema exists"""
        try:
            # Use the initialize_database function we created
            from initialize_database import initialize_comprehensive_database
            conn, cursor = initialize_comprehensive_database()
            conn.close()
            logger.info("‚úÖ Comprehensive database schema ensured")
        except Exception as e:
            logger.error(f"‚ùå Database initialization failed: {e}")
    
    async def load_processed_files(self):
        """Load list of already processed files from database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Create processed_files table if it doesn't exist
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS processed_files (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    filename TEXT UNIQUE NOT NULL,
                    file_hash TEXT,
                    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Load existing processed files
            cursor.execute("SELECT filename FROM processed_files")
            processed = cursor.fetchall()
            
            self.processed_files = set(row[0] for row in processed)
            logger.info(f"üìÅ Loaded {len(self.processed_files)} previously processed files")
            
            conn.commit()
            conn.close()
        except Exception as e:
            logger.error(f"‚ùå Error loading processed files: {e}")
            self.processed_files = set()

    async def mark_file_processed(self, filename: str, file_hash: str = None):
        """Mark a file as processed in the database"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR IGNORE INTO processed_files (filename, file_hash)
                VALUES (?, ?)
            """, (filename, file_hash))
            
            conn.commit()
            conn.close()
            
            self.processed_files.add(filename)
        except Exception as e:
            logger.error(f"‚ùå Error marking file processed: {e}")

    @tasks.loop(minutes=5)  # Check every 5 minutes
    async def monitor_new_files(self):
        """Monitor for new stats files and import them"""
        if not self.is_monitoring or not SSH_AVAILABLE:
            return
            
        try:
            if not self.monitor:
                self.monitor = SSHFileMonitor(
                    self.ssh_host, 
                    self.ssh_user, 
                    self.remote_stats_path,
                    self.ssh_key_path
                )
                
                if not await self.monitor.connect():
                    logger.error("‚ùå SSH connection failed, stopping monitoring")
                    self.is_monitoring = False
                    return
            
            # Get new files
            new_files = await self.monitor.get_new_files()
            
            for remote_file in new_files:
                filename = os.path.basename(remote_file)
                
                # Skip if already processed
                if filename in self.processed_files:
                    continue
                    
                # Download and process
                local_file = os.path.join(self.local_temp_dir, filename)
                
                if await self.monitor.download_file(remote_file, local_file):
                    await self.process_stats_file(local_file, filename)
                    
                    # Clean up local file
                    try:
                        os.remove(local_file)
                    except:
                        pass
                        
        except Exception as e:
            logger.error(f"‚ùå Monitoring error: {e}")

    async def process_stats_file(self, file_path: str, filename: str):
        """Process a downloaded stats file"""
        if not self.parser:
            logger.error("‚ùå Parser not available")
            return
            
        try:
            logger.info(f"üìÑ Processing: {filename}")
            
            # Parse the file
            stats_data = self.parser.parse_stats_file(file_path)
            
            if stats_data.get('error'):
                logger.warning(f"‚ö†Ô∏è Parse error in {filename}: {stats_data['error']}")
                await self.mark_file_processed(filename)
                return
                
            # Store in comprehensive database
            await self.store_comprehensive_data(stats_data, filename)
            
            # Mark as processed
            file_hash = self.calculate_file_hash(file_path)
            await self.mark_file_processed(filename, file_hash)
            
            logger.info(f"‚úÖ Successfully processed: {filename}")
            
        except Exception as e:
            logger.error(f"‚ùå Error processing {filename}: {e}")

    def calculate_file_hash(self, file_path: str) -> str:
        """Calculate MD5 hash of file"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except:
            return None

    async def store_comprehensive_data(self, stats_data: Dict, filename: str):
        """Store parsed stats in comprehensive database"""
        # Implementation similar to our test_bot_import.py
        # This would use the same logic we tested successfully
        pass  # Placeholder - would implement the full storage logic

    async def on_ready(self):
        """Bot ready event"""
        logger.info(f"ü§ñ {self.user} is connected to Discord!")
        logger.info(f"üìä Using comprehensive database: {os.path.basename(self.db_path)}")
        
        if SSH_AVAILABLE:
            logger.info(f"üîó SSH monitoring configured for {self.ssh_user}@{self.ssh_host}:{self.remote_stats_path}")
        else:
            logger.warning("‚ö†Ô∏è SSH monitoring not available - install paramiko and asyncssh")

    # Admin commands for monitoring control
    @commands.command(name='start_monitoring')
    @commands.has_permissions(administrator=True)
    async def start_monitoring(self, ctx):
        """Start SSH file monitoring (Admin only)"""
        if str(ctx.author.id) not in self.admin_users:
            await ctx.send("‚ùå Admin only command")
            return
            
        if not SSH_AVAILABLE:
            await ctx.send("‚ùå SSH libraries not installed")
            return
            
        self.is_monitoring = True
        await ctx.send(f"‚úÖ Started monitoring {self.ssh_user}@{self.ssh_host}:{self.remote_stats_path}")
        logger.info(f"üîç Monitoring started by {ctx.author}")

    @commands.command(name='stop_monitoring')
    @commands.has_permissions(administrator=True)
    async def stop_monitoring(self, ctx):
        """Stop SSH file monitoring (Admin only)"""
        if str(ctx.author.id) not in self.admin_users:
            await ctx.send("‚ùå Admin only command")
            return
            
        self.is_monitoring = False
        if self.monitor:
            await self.monitor.disconnect()
            self.monitor = None
            
        await ctx.send("‚èπÔ∏è Stopped file monitoring")
        logger.info(f"üõë Monitoring stopped by {ctx.author}")

    @commands.command(name='import_status')
    async def import_status(self, ctx):
        """Show import statistics"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM processed_files")
        processed_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM player_comprehensive_stats")
        player_records = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT player_guid) FROM player_comprehensive_stats")
        unique_players = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM player_links")
        discord_links = cursor.fetchone()[0]
        
        conn.close()
        
        embed = discord.Embed(title="üìä Import Status", color=0x0099ff)
        embed.add_field(name="üìÅ Files Processed", value=f"{processed_count:,}", inline=True)
        embed.add_field(name="üë§ Player Records", value=f"{player_records:,}", inline=True)
        embed.add_field(name="üÜî Unique Players", value=f"{unique_players:,}", inline=True)
        embed.add_field(name="üîó Discord Links", value=f"{discord_links:,}", inline=True)
        embed.add_field(name="üîç Monitoring", value="‚úÖ Active" if self.is_monitoring else "‚èπÔ∏è Stopped", inline=True)
        embed.set_footer(text="Production ET:Legacy Bot")
        
        await ctx.send(embed=embed)

async def main():
    """Start the production bot"""
    token = os.getenv('DISCORD_BOT_TOKEN')
    if not token:
        logger.error("‚ùå DISCORD_BOT_TOKEN not found in environment")
        return
        
    bot = ProductionETLegacyBot()
    
    try:
        await bot.start(token)
    except Exception as e:
        logger.error(f"‚ùå Bot startup failed: {e}")

if __name__ == "__main__":
    asyncio.run(main())