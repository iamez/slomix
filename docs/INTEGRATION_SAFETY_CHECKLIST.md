# Integration Safety Checklist & Rollback Strategy
**Competitive Analytics System Integration**
*Generated: 2025-11-28*

---

## Document Purpose

This document provides a comprehensive pre-flight checklist and rollback procedures for safely integrating the competitive analytics system into production. Use this as a go/no-go decision framework before each deployment phase.

---

## Table of Contents

1. [Pre-Integration Checklist](#pre-integration-checklist)
2. [Phase-Specific Checklists](#phase-specific-checklists)
3. [Rollback Strategy](#rollback-strategy)
4. [Emergency Procedures](#emergency-procedures)
5. [Post-Deployment Monitoring](#post-deployment-monitoring)
6. [Go/No-Go Decision Framework](#gono-go-decision-framework)

---

## Pre-Integration Checklist

### Environment Preparation

#### Database Backup
- [ ] Full PostgreSQL backup completed
  ```bash
  # Backup command
  pg_dump -h localhost -U etlegacy_user -d etlegacy > \
    etlegacy_production_backup_$(date +%Y%m%d_%H%M%S).sql

  # Verify backup size (should be >10 MB)
  ls -lh etlegacy_production_backup_*.sql
  ```
- [ ] Backup stored in safe location (off-server)
- [ ] Backup tested (able to restore to test database)
- [ ] Backup retention: Keep last 7 days

#### Git Repository State
- [ ] All changes committed to feature branch
  ```bash
  git status  # Should show "nothing to commit, working tree clean"
  ```
- [ ] Feature branch: `feature/competitive-analytics` created
- [ ] Current commit tagged: `pre-competitive-analytics-v1.0`
  ```bash
  git tag pre-competitive-analytics-v1.0
  git push origin pre-competitive-analytics-v1.0
  ```
- [ ] Remote repository up to date
- [ ] No uncommitted changes in production branch

#### Test Environment
- [ ] Test server running (separate from production)
- [ ] Test database seeded with production data copy
- [ ] Test Discord bot token configured
- [ ] Test environment matches production (Python version, dependencies)
- [ ] Test channels configured for output verification

#### Configuration Management
- [ ] Feature flags added to `bot/config.py`
  ```python
  # Feature Flags for Competitive Analytics
  ENABLE_TEAM_SPLIT_DETECTION = False  # Default: OFF
  ENABLE_MATCH_PREDICTIONS = False     # Default: OFF
  ENABLE_LIVE_SCORING = False          # Default: OFF
  ENABLE_PREDICTION_LOGGING = True     # Always on for debugging
  ```
- [ ] Environment variables documented
- [ ] Config changes backward compatible (bot runs with flags OFF)
- [ ] Rollback config prepared (revert flags to OFF)

#### Dependencies
- [ ] Python 3.10+ confirmed
  ```bash
  python --version  # Should be 3.10 or higher
  ```
- [ ] All dependencies installed
  ```bash
  pip install -r requirements.txt
  ```
- [ ] No dependency conflicts
  ```bash
  pip check  # Should show "No broken requirements found"
  ```
- [ ] PostgreSQL 14+ confirmed
  ```bash
  psql --version  # Should be 14 or higher
  ```

#### Code Review
- [ ] All code reviewed (preferably by second person)
- [ ] No `TODO` or `FIXME` comments in critical paths
- [ ] Error handling present in all async functions
- [ ] Logging statements added for debugging
- [ ] No hardcoded credentials or tokens
- [ ] Type hints present (mypy clean)

---

## Phase-Specific Checklists

### Phase 1: Database Adapter Refactoring

#### Pre-Deployment
- [ ] **Refactor team_manager.py**
  - [ ] All `sqlite3.Connection` replaced with `db_adapter`
  - [ ] All `cursor.execute()` replaced with `db_adapter.fetch_*()`
  - [ ] All methods converted to `async`
  - [ ] Parameterized queries use adapter syntax
  - [ ] Unit tests pass
- [ ] **Refactor advanced_team_detector.py**
  - [ ] Same changes as team_manager.py
  - [ ] Historical analysis query tested
  - [ ] Consensus analysis query tested
- [ ] **Refactor substitution_detector.py**
  - [ ] Same changes as above
  - [ ] Roster change detection tested

#### Testing
- [ ] Unit tests written for each refactored method
- [ ] Integration test: `!team` command works
- [ ] Integration test: `!teams 2025-11-20` works (historical date)
- [ ] Integration test: Team detection runs on test session
- [ ] No database errors in logs
- [ ] No performance regression (<2s response time)

#### Deployment
- [ ] Deploy to test server first
- [ ] Run for 24 hours on test server
- [ ] Monitor logs for errors
- [ ] Verify `!team` command output matches expected
- [ ] Deploy to production
- [ ] Monitor production logs for 2 hours
- [ ] Verify `!team` command works in production

#### Rollback Criteria
- [ ] IF `!team` command fails ‚Üí **ROLLBACK**
- [ ] IF database errors appear ‚Üí **ROLLBACK**
- [ ] IF response time >5 seconds ‚Üí **ROLLBACK**

---

### Phase 2: Voice Channel Enhancement

#### Pre-Deployment
- [ ] **Create new database tables**
  ```sql
  -- Execute these on TEST database first
  CREATE TABLE IF NOT EXISTS lineup_performance (...);
  CREATE TABLE IF NOT EXISTS head_to_head_matchups (...);
  CREATE TABLE IF NOT EXISTS map_performance (...);
  CREATE TABLE IF NOT EXISTS match_predictions (...);
  ```
- [ ] **Verify table creation**
  ```sql
  \dt  -- Should show all 4 new tables
  \d lineup_performance  -- Verify schema
  ```
- [ ] **Enhance voice_session_service.py**
  - [ ] `_detect_team_split()` method added
  - [ ] `channel_distribution` tracking added
  - [ ] `resolve_discord_ids_to_guids()` method added
  - [ ] Logging statements added for debugging
  - [ ] Feature flag checked before team split detection
- [ ] **Add GUID mapping query**
  - [ ] Query tested on test database
  - [ ] Returns expected Discord ID ‚Üí GUID mappings
  - [ ] Handles missing entries gracefully

#### Testing
- [ ] **Manual voice channel test:**
  - [ ] Join voice channel with 6+ test accounts
  - [ ] Split into 2 channels (3+3)
  - [ ] Verify team split detected in logs
  - [ ] Verify GUID resolution works
  - [ ] Verify no false positives (players leaving ‚â† split)
- [ ] **Edge cases:**
  - [ ] Test unbalanced split (4+2)
  - [ ] Test >2 channels active
  - [ ] Test users without linked GUIDs
  - [ ] Test rapid join/leave (don't trigger false split)
- [ ] **Bot restart test:**
  - [ ] Start bot with players in voice
  - [ ] Verify no false team split trigger
  - [ ] Verify session resumes correctly

#### Deployment
- [ ] Enable feature flag on test server:
  ```python
  ENABLE_TEAM_SPLIT_DETECTION = True
  ```
- [ ] Test for 48 hours with live voice activity
- [ ] Verify logs show team split events
- [ ] Verify no false positives
- [ ] Deploy to production with flag **OFF**
- [ ] Monitor for 24 hours (ensure no regressions)
- [ ] Enable flag in production:
  ```python
  ENABLE_TEAM_SPLIT_DETECTION = True
  ```
- [ ] Monitor for team split events

#### Rollback Criteria
- [ ] IF false positives detected (split when none occurred) ‚Üí **ROLLBACK**
- [ ] IF voice state updates lag >500ms ‚Üí **ROLLBACK**
- [ ] IF bot crashes on voice event ‚Üí **ROLLBACK**

---

### Phase 3: Prediction Engine

#### Pre-Deployment
- [ ] **Create PredictionEngine service**
  - [ ] `predict_match()` method implemented
  - [ ] `_analyze_head_to_head()` implemented and tested
  - [ ] `_analyze_recent_form()` implemented and tested
  - [ ] `_analyze_map_performance()` implemented and tested
  - [ ] `_analyze_substitution_impact()` implemented and tested
  - [ ] Weighted scoring logic verified
  - [ ] Confidence calculation verified
- [ ] **Create prediction embed template**
  - [ ] Discord embed formatted correctly
  - [ ] All factor details displayed
  - [ ] Confidence shown as percentage
  - [ ] Team rosters listed
- [ ] **Test with historical data**
  - [ ] Run predictions on 10 past sessions
  - [ ] Verify output format
  - [ ] Verify factor scores make sense
  - [ ] Calculate baseline accuracy (should be >50%)

#### Testing
- [ ] **Unit tests:**
  - [ ] H2H analysis with mock data
  - [ ] Form analysis with mock data
  - [ ] Map performance with mock data
  - [ ] Weighted combination logic
- [ ] **Integration tests:**
  - [ ] Full prediction flow (team split ‚Üí prediction ‚Üí post)
  - [ ] Verify embed posted to correct channel
  - [ ] Verify prediction stored in database
  - [ ] Verify no crashes on edge cases (no data, tie scenarios)
- [ ] **Accuracy test:**
  - [ ] Run predictions on 20 historical sessions
  - [ ] Compare predicted vs actual outcomes
  - [ ] Calculate accuracy (target >60%)

#### Deployment
- [ ] Deploy to test server with flag **OFF**
- [ ] Enable prediction flag on test server:
  ```python
  ENABLE_MATCH_PREDICTIONS = True
  ```
- [ ] Trigger test prediction manually (simulate team split)
- [ ] Verify embed posted
- [ ] Verify prediction stored in database
- [ ] Monitor for 72 hours with live sessions
- [ ] Deploy to production with flag **OFF**
- [ ] Enable flag in production:
  ```python
  ENABLE_MATCH_PREDICTIONS = True
  ```
- [ ] Monitor first 5 predictions carefully

#### Rollback Criteria
- [ ] IF prediction generation >5 seconds ‚Üí **ROLLBACK**
- [ ] IF database errors during prediction ‚Üí **ROLLBACK**
- [ ] IF incorrect team assignments in prediction ‚Üí **ROLLBACK**
- [ ] IF accuracy <40% after 20 predictions ‚Üí **TUNE WEIGHTS**

---

### Phase 4: Live Scoring

#### Pre-Deployment
- [ ] **Connect prediction to SSH monitor**
  - [ ] Detect when R1/R2 files arrive
  - [ ] Parse stopwatch scores
  - [ ] Match rounds to predictions
  - [ ] Update `match_predictions` table with actual winner
- [ ] **Create result embed template**
  - [ ] Show predicted vs actual winner
  - [ ] Highlight if prediction correct ‚úÖ or incorrect ‚ùå
  - [ ] Show final score
- [ ] **Test with historical files**
  - [ ] Process 10 R1/R2 file pairs
  - [ ] Verify scores parsed correctly
  - [ ] Verify predictions updated

#### Testing
- [ ] **Manual test:**
  - [ ] Generate prediction for test session
  - [ ] Import R1/R2 files manually
  - [ ] Verify result embed posted
  - [ ] Verify prediction updated correctly
- [ ] **Automation test:**
  - [ ] SSH monitor detects new files
  - [ ] Scores auto-parsed
  - [ ] Results auto-posted
  - [ ] No manual intervention needed

#### Deployment
- [ ] Deploy to test server
- [ ] Enable live scoring flag:
  ```python
  ENABLE_LIVE_SCORING = True
  ```
- [ ] Monitor for 1 week
- [ ] Deploy to production with flag **OFF**
- [ ] Enable in production after 24 hours

#### Rollback Criteria
- [ ] IF scores parsed incorrectly ‚Üí **ROLLBACK**
- [ ] IF predictions not updated ‚Üí **ROLLBACK**
- [ ] IF spam posts (multiple results for same match) ‚Üí **ROLLBACK**

---

### Phase 5: Refinement

#### Pre-Deployment
- [ ] **Calculate prediction accuracy**
  ```sql
  SELECT
    COUNT(*) as total,
    SUM(CASE WHEN prediction_correct THEN 1 ELSE 0 END) as correct,
    ROUND(100.0 * SUM(CASE WHEN prediction_correct THEN 1 ELSE 0 END) / COUNT(*), 2) as accuracy
  FROM match_predictions
  WHERE actual_winner IS NOT NULL;
  ```
- [ ] **Tune weights if needed**
  - [ ] If accuracy <60%, adjust weights
  - [ ] Rerun historical predictions
  - [ ] Compare new accuracy
- [ ] **Optimize slow queries**
  - [ ] Check slow query log
  - [ ] Run EXPLAIN ANALYZE on slow queries
  - [ ] Add indexes if needed
- [ ] **Cache optimization**
  - [ ] Measure cache hit rate
  - [ ] Adjust cache size if needed
  - [ ] Tune TTL if stale data detected

#### Testing
- [ ] **Performance testing:**
  - [ ] Load test: 12 players, 8 maps, 4 hours
  - [ ] Measure prediction latency (should be <2s)
  - [ ] Measure memory usage (should be <250 MB)
  - [ ] Verify no memory leaks
- [ ] **Accuracy validation:**
  - [ ] Compare predictions vs actuals for 30 matches
  - [ ] Calculate confidence-weighted accuracy
  - [ ] Verify high-confidence predictions more accurate

#### Deployment
- [ ] Deploy optimizations to test server
- [ ] Run for 1 week
- [ ] Deploy to production
- [ ] Monitor for 1 month

#### Success Criteria
- [ ] Accuracy >60% overall
- [ ] High-confidence (>75%) predictions >70% accurate
- [ ] Prediction latency <2 seconds
- [ ] Memory stable <250 MB
- [ ] No database timeouts

---

## Rollback Strategy

### Rollback Levels

#### Level 1: Feature Flag Disable (Fastest - 2 minutes)
**When to use:** Minor issues, no data corruption, can try again later

**Procedure:**
1. SSH to production server
   ```bash
   ssh user@production-server
   cd /path/to/slomix_discord
   ```

2. Edit config file
   ```bash
   nano bot/config.py
   ```

3. Disable feature flags
   ```python
   ENABLE_TEAM_SPLIT_DETECTION = False
   ENABLE_MATCH_PREDICTIONS = False
   ENABLE_LIVE_SCORING = False
   ```

4. Restart bot
   ```bash
   systemctl restart slomix-bot
   # OR
   screen -r slomix-bot
   # Ctrl+C to stop, then restart with start script
   ```

5. Verify bot operational
   ```bash
   # Check logs
   tail -f bot_logs/bot.log

   # Test basic command
   # In Discord: !ping or !last_session
   ```

**Rollback Time:** 2-5 minutes
**Data Loss:** None (tables remain, just unused)
**Risk:** LOW

---

#### Level 2: Git Revert (Moderate - 10 minutes)
**When to use:** Code bugs, crashes, cannot fix quickly

**Procedure:**
1. SSH to production server
   ```bash
   ssh user@production-server
   cd /path/to/slomix_discord
   ```

2. Stop bot
   ```bash
   systemctl stop slomix-bot
   # OR
   screen -r slomix-bot
   # Ctrl+C
   ```

3. Git revert to pre-integration tag
   ```bash
   git status  # Check current state
   git log --oneline -10  # Verify commits

   # Revert to tagged commit
   git checkout pre-competitive-analytics-v1.0

   # OR create revert commit (preserves history)
   git revert HEAD~5..HEAD  # Revert last 5 commits
   ```

4. Restart bot
   ```bash
   systemctl start slomix-bot
   # OR
   screen -S slomix-bot
   ./start_bot.sh
   ```

5. Verify bot operational
   ```bash
   tail -f bot_logs/bot.log
   ```

**Rollback Time:** 10-15 minutes
**Data Loss:** None (database untouched)
**Risk:** LOW

---

#### Level 3: Database Rollback (Slow - 30-60 minutes)
**When to use:** Data corruption, bad migrations, need full state restore

**Procedure:**
1. **CRITICAL: Take snapshot before rollback**
   ```bash
   pg_dump -h localhost -U etlegacy_user -d etlegacy > \
     etlegacy_pre_rollback_$(date +%Y%m%d_%H%M%S).sql
   ```

2. Stop bot
   ```bash
   systemctl stop slomix-bot
   ```

3. Restore database from backup
   ```bash
   # Drop existing database
   psql -h localhost -U postgres -c "DROP DATABASE etlegacy;"

   # Recreate database
   psql -h localhost -U postgres -c "CREATE DATABASE etlegacy OWNER etlegacy_user;"

   # Restore from backup
   psql -h localhost -U etlegacy_user -d etlegacy < \
     etlegacy_production_backup_YYYYMMDD_HHMMSS.sql

   # Verify restoration
   psql -h localhost -U etlegacy_user -d etlegacy -c "\dt"
   ```

4. Git revert code
   ```bash
   cd /path/to/slomix_discord
   git checkout pre-competitive-analytics-v1.0
   ```

5. Restart bot
   ```bash
   systemctl start slomix-bot
   ```

6. Verify bot operational
   ```bash
   tail -f bot_logs/bot.log

   # Test commands in Discord
   # !last_session, !player_stats
   ```

**Rollback Time:** 30-60 minutes (depends on database size)
**Data Loss:** ALL changes since backup (could lose hours of data)
**Risk:** MEDIUM (data loss risk)

---

#### Level 4: Full System Restore (Emergency - 2-4 hours)
**When to use:** Complete system failure, multiple cascading issues

**Procedure:**
1. **Notify users:** Post maintenance message in Discord

2. **Full server snapshot** (if VM/cloud)
   ```bash
   # AWS example
   aws ec2 create-snapshot --volume-id vol-xxx --description "Pre-rollback snapshot"
   ```

3. **Stop all services**
   ```bash
   systemctl stop slomix-bot
   systemctl stop postgresql
   ```

4. **Restore from server backup** (varies by infrastructure)

5. **Verify restoration**
   ```bash
   # Check database
   psql -h localhost -U etlegacy_user -d etlegacy -c "SELECT COUNT(*) FROM rounds;"

   # Check code
   git log -1

   # Check config
   cat bot/config.py | grep database_type
   ```

6. **Restart services**
   ```bash
   systemctl start postgresql
   systemctl start slomix-bot
   ```

7. **Full system test**
   - Test all !commands
   - Monitor voice detection
   - Check SSH monitor
   - Verify file imports

**Rollback Time:** 2-4 hours
**Data Loss:** Potentially significant
**Risk:** HIGH

---

### Rollback Decision Tree

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Issue Detected  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                 ‚îÇ  Is bot responsive?   ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ YES                        NO‚îÇ
              ‚ñº                              ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Is data corrupt? ‚îÇ           ‚îÇ Level 4: Full   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ System Restore  ‚îÇ
             ‚îÇ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ YES        NO‚îÇ
      ‚ñº              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Level 3: ‚îÇ  ‚îÇ Is it a code ‚îÇ
‚îÇ Database ‚îÇ  ‚îÇ bug/crash?   ‚îÇ
‚îÇ Rollback ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ YES        NO‚îÇ
              ‚ñº              ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ Level 2: ‚îÇ  ‚îÇ Level 1:     ‚îÇ
       ‚îÇ Git      ‚îÇ  ‚îÇ Feature Flag ‚îÇ
       ‚îÇ Revert   ‚îÇ  ‚îÇ Disable      ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Emergency Procedures

### Emergency Contact Protocol

**In order of escalation:**
1. **Primary Admin** (Discord username: @PrimaryAdmin)
   - Responsible for: Feature flags, git operations
   - Available: 24/7 (ping in #admin channel)

2. **Database Admin** (if different)
   - Responsible for: Database rollbacks, query optimization
   - Available: Business hours (ping for emergencies)

3. **Community notification**
   - Channel: #announcements
   - Template message:
     ```
     üö® **Bot Maintenance**

     We're experiencing technical difficulties with the bot.
     Commands may be unavailable for ~30 minutes while we
     investigate and resolve the issue.

     Thank you for your patience!
     ```

### Critical Error Responses

#### Bot Crash Loop
**Symptoms:** Bot repeatedly crashes and restarts

**Response:**
1. Stop bot immediately
   ```bash
   systemctl stop slomix-bot
   ```

2. Check logs for error
   ```bash
   tail -100 bot_logs/bot.log | grep -i error
   ```

3. IF error in new code ‚Üí Level 2 Rollback (Git Revert)
4. IF error in existing code ‚Üí Investigate, fix, restart

#### Database Connection Exhaustion
**Symptoms:** "Too many connections" errors in logs

**Response:**
1. Check active connections
   ```sql
   SELECT COUNT(*) FROM pg_stat_activity WHERE datname = 'etlegacy';
   ```

2. Kill idle connections
   ```sql
   SELECT pg_terminate_backend(pid)
   FROM pg_stat_activity
   WHERE datname = 'etlegacy'
     AND state = 'idle'
     AND state_change < NOW() - INTERVAL '5 minutes';
   ```

3. IF issue persists ‚Üí Disable feature flags (Level 1 Rollback)

4. Review connection pool settings
   ```python
   # bot/ultimate_bot.py
   min_pool_size=10  # Maybe increase?
   max_pool_size=30
   ```

#### Discord Rate Limit Hit
**Symptoms:** "Rate limited" errors, messages not posting

**Response:**
1. Disable live scoring immediately
   ```python
   ENABLE_LIVE_SCORING = False
   ```

2. Check rate limit logs
   ```bash
   grep -i "rate limit" bot_logs/bot.log
   ```

3. Identify offending code (likely prediction/result posts)

4. Implement rate limiting wrapper (see PERFORMANCE_IMPACT_ANALYSIS.md)

5. Re-enable gradually

#### False Predictions
**Symptoms:** Predictions wildly inaccurate (0% correct after 10 matches)

**Response:**
1. Disable predictions
   ```python
   ENABLE_MATCH_PREDICTIONS = False
   ```

2. Review prediction logic
   - Check H2H query results
   - Verify team GUID mappings
   - Review weight calculations

3. Test with historical data
   ```python
   # Manual prediction test
   python -m bot.services.prediction_engine 2025-11-20
   ```

4. Fix logic, test thoroughly, re-enable

#### Data Corruption
**Symptoms:** Incorrect data in prediction tables, inconsistent state

**Response:**
1. **STOP BOT IMMEDIATELY**
   ```bash
   systemctl stop slomix-bot
   ```

2. **Take database snapshot**
   ```bash
   pg_dump -h localhost -U etlegacy_user -d etlegacy > emergency_snapshot.sql
   ```

3. **Assess damage**
   ```sql
   -- Check prediction tables
   SELECT COUNT(*) FROM match_predictions WHERE confidence > 1.0;  -- Should be 0
   SELECT COUNT(*) FROM match_predictions WHERE confidence < 0.0;  -- Should be 0

   -- Check for duplicate entries
   SELECT team_a_guids, team_b_guids, COUNT(*)
   FROM match_predictions
   GROUP BY team_a_guids, team_b_guids, session_start_date
   HAVING COUNT(*) > 1;
   ```

4. **IF core tables (rounds, player_stats) affected ‚Üí Level 3 Rollback**
5. **IF only prediction tables affected ‚Üí Truncate and rebuild**
   ```sql
   TRUNCATE match_predictions;
   TRUNCATE lineup_performance;
   TRUNCATE head_to_head_matchups;
   TRUNCATE map_performance;
   ```

6. **Restart bot, rebuild data from scratch**

---

## Post-Deployment Monitoring

### First 24 Hours (Critical Monitoring)

**Check every 2 hours:**
- [ ] Bot is running (uptime check)
- [ ] No error spikes in logs
  ```bash
  grep -c "ERROR" bot_logs/bot.log  # Count errors
  ```
- [ ] Discord commands working (!ping, !last_session)
- [ ] Voice detection working (if enabled)
- [ ] Predictions posted correctly (if enabled)
- [ ] Database connections stable
  ```sql
  SELECT COUNT(*) FROM pg_stat_activity WHERE datname = 'etlegacy';
  ```
- [ ] Memory usage stable
  ```bash
  ps aux | grep python | awk '{print $6/1024 " MB"}'
  ```

### First Week (Active Monitoring)

**Check daily:**
- [ ] Review logs for warnings
  ```bash
  grep "WARNING\|ERROR" bot_logs/bot.log | tail -50
  ```
- [ ] Check prediction accuracy
  ```sql
  SELECT
    COUNT(*) as total,
    AVG(CASE WHEN prediction_correct THEN 1.0 ELSE 0.0 END) as accuracy
  FROM match_predictions
  WHERE actual_winner IS NOT NULL
    AND prediction_time > NOW() - INTERVAL '7 days';
  ```
- [ ] Review performance metrics
  ```bash
  grep "Prediction generated in" bot_logs/bot.log | tail -20
  ```
- [ ] Check database size growth
  ```sql
  SELECT pg_size_pretty(pg_database_size('etlegacy'));
  ```
- [ ] Review false positive rate (team splits that weren't real)
  ```bash
  grep "Team split detected" bot_logs/bot.log | wc -l
  # Compare to actual session count
  ```

### First Month (Passive Monitoring)

**Check weekly:**
- [ ] Overall system health
- [ ] Prediction accuracy trend
- [ ] User feedback (Discord reactions/comments)
- [ ] Feature flag status (any still disabled?)
- [ ] Database performance (slow queries?)
- [ ] Memory usage trend (any leaks?)

### Automated Monitoring (Setup)

**Recommended tools:**
1. **Uptime monitoring:** UptimeRobot or similar
2. **Log monitoring:** Logtail or Papertrail
3. **Alerting:** Discord webhooks for critical errors

**Alert Setup Example:**
```python
# bot/logging_config.py
import requests

class DiscordWebhookHandler(logging.Handler):
    def __init__(self, webhook_url):
        super().__init__()
        self.webhook_url = webhook_url
        self.setLevel(logging.ERROR)  # Only ERROR and CRITICAL

    def emit(self, record):
        message = self.format(record)
        payload = {
            "content": f"üö® **Bot Error Alert**\n```{message}```"
        }
        requests.post(self.webhook_url, json=payload)

# Add to logger
webhook_handler = DiscordWebhookHandler(WEBHOOK_URL)
logger.addHandler(webhook_handler)
```

---

## Go/No-Go Decision Framework

### Phase 1: Database Adapter Refactoring

**GO if:**
- ‚úÖ All unit tests pass
- ‚úÖ Integration tests pass on test server
- ‚úÖ !team command works correctly
- ‚úÖ No performance regression (<2s response)
- ‚úÖ Code reviewed by second person
- ‚úÖ Backup completed

**NO-GO if:**
- ‚ùå Any test fails
- ‚ùå Response time >5 seconds
- ‚ùå Database errors in test
- ‚ùå Backup failed or not tested

---

### Phase 2: Voice Channel Enhancement

**GO if:**
- ‚úÖ Phase 1 stable for 1 week
- ‚úÖ Manual voice test successful
- ‚úÖ Edge cases tested (unbalanced, >2 channels, etc.)
- ‚úÖ No false positives in test
- ‚úÖ Bot restart test passed
- ‚úÖ Feature flag tested (can disable)

**NO-GO if:**
- ‚ùå False positives detected
- ‚ùå Voice state lag >500ms
- ‚ùå Bot crashes on voice event
- ‚ùå Phase 1 not stable

---

### Phase 3: Prediction Engine

**GO if:**
- ‚úÖ Phase 2 stable for 1 week
- ‚úÖ Historical accuracy test >50%
- ‚úÖ Prediction generation <5 seconds
- ‚úÖ All factor analyses work correctly
- ‚úÖ Discord embed posts correctly
- ‚úÖ Prediction stored in database
- ‚úÖ 72 hours test server success

**NO-GO if:**
- ‚ùå Historical accuracy <40%
- ‚ùå Prediction generation >10 seconds
- ‚ùå Database errors during prediction
- ‚ùå Embed format broken
- ‚ùå Phase 2 not stable

---

### Phase 4: Live Scoring

**GO if:**
- ‚úÖ Phase 3 stable for 2 weeks
- ‚úÖ Prediction accuracy >55%
- ‚úÖ Score parsing tested with 10+ files
- ‚úÖ Predictions updated correctly
- ‚úÖ Result embeds post correctly
- ‚úÖ No duplicate posts in test

**NO-GO if:**
- ‚ùå Scores parsed incorrectly
- ‚ùå Predictions not updated
- ‚ùå Duplicate result posts
- ‚ùå Prediction accuracy <45%
- ‚ùå Phase 3 not stable

---

### Phase 5: Refinement

**GO if:**
- ‚úÖ All previous phases stable
- ‚úÖ Prediction accuracy >60% (target met)
- ‚úÖ Performance acceptable (<2s predictions)
- ‚úÖ Memory stable (<250 MB)
- ‚úÖ User feedback positive
- ‚úÖ No critical bugs reported

**NO-GO if:**
- ‚ùå Accuracy still <55%
- ‚ùå Performance degraded
- ‚ùå Memory leaks detected
- ‚ùå User complaints about false predictions
- ‚ùå Any phase unstable

---

## Success Criteria Summary

### Technical Metrics
- ‚úÖ Prediction accuracy: >60% overall
- ‚úÖ High-confidence predictions: >70% accurate
- ‚úÖ Prediction latency: <2 seconds
- ‚úÖ Memory usage: <250 MB
- ‚úÖ Database queries: <100ms each
- ‚úÖ No crashes for 30 days
- ‚úÖ Uptime: >99%

### User Experience Metrics
- ‚úÖ Predictions posted automatically for >80% of sessions
- ‚úÖ No false positives (team split when none occurred)
- ‚úÖ No user complaints about spam
- ‚úÖ Positive Discord reactions to predictions
- ‚úÖ Predictions add value (users engage with them)

### Operational Metrics
- ‚úÖ No manual intervention required
- ‚úÖ Rollback procedure tested and works
- ‚úÖ Monitoring in place and functional
- ‚úÖ Documentation complete and accurate
- ‚úÖ Team trained on rollback procedures

---

## Final Checklist Before Production

### Pre-Flight Check (Day of Production Deployment)

**T-2 hours:**
- [ ] Backup database (verified)
- [ ] Git tag created
- [ ] Feature flags OFF
- [ ] Test server running for 48+ hours successfully
- [ ] All team members notified
- [ ] Discord maintenance message prepared (don't send yet)

**T-1 hour:**
- [ ] Review deployment plan
- [ ] Confirm rollback contact available
- [ ] Check server load (deploy during off-peak)
- [ ] Verify no other deployments in progress

**T-0 (Deployment):**
- [ ] Post maintenance message (if needed)
- [ ] Stop bot
- [ ] Git pull new code
- [ ] Restart bot (with flags OFF)
- [ ] Verify bot started
- [ ] Test !ping command
- [ ] Enable Phase 1 features
- [ ] Monitor for 30 minutes
- [ ] IF all good ‚Üí post completion message

**T+30 minutes:**
- [ ] Review logs
- [ ] Check for errors
- [ ] Test all commands
- [ ] IF all good ‚Üí deployment successful ‚úÖ
- [ ] IF issues ‚Üí execute rollback

---

**Document End**
